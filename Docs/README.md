# ğŸ™ï¸ AI Voice Detection API

Detects AI-generated vs Human voices across 5 Indian languages.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run the server
uvicorn main:app --reload --port 8000
```

## ğŸ“¡ API Usage

### Endpoint
```
POST /api/voice-detection
```

### Headers
| Header | Value |
|--------|-------|
| Content-Type | application/json |
| x-api-key | AEGON_2050 |

### Request Body
```json
{
  "language": "Tamil",
  "audioFormat": "mp3",
  "audioBase64": "BASE64_ENCODED_AUDIO"
}
```

### Success Response
```json
{
  "status": "success",
  "language": "Tamil",
  "classification": "AI_GENERATED",
  "confidenceScore": 0.85,
  "explanation": "Unnatural pitch consistency; Low spectral variance"
}
```

### Error Response
```json
{
  "status": "error",
  "message": "Invalid API key"
}
```

## ğŸ—£ï¸ Supported Languages
- Tamil
- English
- Hindi
- Malayalam  
- Telugu

## ğŸ”§ Environment Variables
| Variable | Description | Default |
|----------|-------------|---------|
| API_KEY | API authentication key | AEGON_2050 |

## ğŸ“¦ Project Structure
```
AI_Voice_Detection/
â”œâ”€â”€ main.py              # FastAPI application
â”œâ”€â”€ audio_processor.py   # ML audio classification
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ render.yaml          # Render deployment config
â”œâ”€â”€ Procfile             # Railway/Heroku config
â”œâ”€â”€ .env                 # Environment variables
â”œâ”€â”€ .env.example         # Env template
â”œâ”€â”€ .gitignore           # Git ignore rules
â””â”€â”€ Docs/                # Documentation
```

## ğŸš¢ Deployment

### Render (Recommended)
1. Push code to GitHub
2. Connect Render to repo
3. Add environment variable: `API_KEY=AEGON_2050`
4. Deploy (auto-builds from render.yaml)

### Railway
```bash
railway login
railway init
railway up
railway variables set API_KEY=AEGON_2050
```

## ğŸ§ª Testing

### Test with curl
```bash
curl -X POST http://localhost:8000/api/voice-detection \
  -H "Content-Type: application/json" \
  -H "x-api-key: AEGON_2050" \
  -d '{"language": "English", "audioFormat": "mp3", "audioBase64": "..."}'
```

### Test with provided 'test_sample'
I've included a script to automatically test the samples provided in the `test_sample` folder:

```bash
python verify_sample.py
```

This will:
1. Take `test_sample/sample voice 1.mp3`
2. Convert it to Base64
3. Send it to the API
4. Tell you if it's AI or HUMAN

### Health Check
```bash
curl http://localhost:8000/health
```

## âœ… Validation Checklist
- [x] Endpoint URL is live
- [x] x-api-key header authentication works
- [x] Accepts all 5 languages
- [x] Returns proper JSON structure
- [x] classification is "AI_GENERATED" or "HUMAN"
- [x] confidenceScore is between 0.0-1.0
- [x] explanation field is present
- [x] Error responses return proper JSON

## ğŸ” How It Works
The API uses librosa for audio feature extraction:
- **MFCCs** - Spectral shape
- **Pitch variation** - AI voices have less variation
- **Spectral flatness** - AI voices are flatter
- **Zero crossing rate** - Rhythm patterns
- **RMS Energy** - Volume consistency

AI voices typically show: low spectral variance, consistent pitch, uniform energy.

## ğŸ“œ License
MIT License
